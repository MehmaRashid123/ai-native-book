"use strict";(globalThis.webpackChunkphysical_ai_handbook=globalThis.webpackChunkphysical_ai_handbook||[]).push([[929],{2907:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>u,frontMatter:()=>t,metadata:()=>a,toc:()=>c});var o=i(4848),s=i(8453);const t={sidebar_position:3},l="LLM Cognitive Planning",a={id:"module-4/llm-planning",title:"LLM Cognitive Planning",description:"Large Language Models (LLMs) can be used for high-level cognitive planning in robotics, enabling robots to understand complex tasks and generate action sequences.",source:"@site/docs/module-4/llm-planning.md",sourceDirName:"module-4",slug:"/module-4/llm-planning",permalink:"/ur/docs/module-4/llm-planning",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4/llm-planning.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Module 4: Vision-Language-Action (VLA)",permalink:"/ur/docs/module-4/whisper-voice"},next:{title:"Capstone: Autonomous Humanoid",permalink:"/ur/docs/module-4/capstone"}},r={},c=[{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"LLMs in Robotics",id:"llms-in-robotics",level:2},{value:"Planning with LLMs",id:"planning-with-llms",level:2}];function d(n){const e={h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"llm-cognitive-planning",children:"LLM Cognitive Planning"}),"\n",(0,o.jsx)(e.p,{children:"Large Language Models (LLMs) can be used for high-level cognitive planning in robotics, enabling robots to understand complex tasks and generate action sequences."}),"\n",(0,o.jsx)(e.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Integration of LLMs with robotic systems"}),"\n",(0,o.jsx)(e.li,{children:"Task decomposition and planning"}),"\n",(0,o.jsx)(e.li,{children:"Natural language interfaces for robots"}),"\n",(0,o.jsx)(e.li,{children:"Cognitive architectures for embodied AI"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Understanding of Vision-Language-Action concepts"}),"\n",(0,o.jsx)(e.li,{children:"Basic knowledge of neural networks"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"llms-in-robotics",children:"LLMs in Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Large Language Models can serve as cognitive controllers for robots, interpreting high-level commands and generating sequences of actions to achieve complex goals..."}),"\n",(0,o.jsx)(e.h2,{id:"planning-with-llms",children:"Planning with LLMs"}),"\n",(0,o.jsx)(e.p,{children:"LLMs can decompose complex tasks into simpler subtasks that can be executed by robotic systems."})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>l,x:()=>a});var o=i(6540);const s={},t=o.createContext(s);function l(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:l(n.components),o.createElement(t.Provider,{value:e},n.children)}}}]);